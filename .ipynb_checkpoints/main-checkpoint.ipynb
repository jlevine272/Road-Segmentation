{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ab2784b-ac8f-4efc-aeb0-b3c284b498b5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torchvision.datasets import Cityscapes\n",
    "import os\n",
    "from glob import glob\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import make_grid\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from einops import rearrange\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "import torchvision\n",
    "from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation\n",
    "from labels import id2label, label2id, id2color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cfc479-82ff-456e-bc8b-12d813c66e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.image_list = os.listdir(data_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.data_dir, self.image_list[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "from segment_proj import test, DRNSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "779d5e64-9fa9-4f52-8456-9c79e57ddcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# im_dir = 'datasets/cityscapes/cityscapes/leftImg8bit/test/berlin'\n",
    "im_dir = 'datasets/small'\n",
    "MODEL_PATH = \"drn_d_22_cityscapes.pth\"\n",
    "phase = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ea8f4e-abd3-451b-811d-27c0b0829f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model = DRNSeg(\"drn_d_22\", 19, pretrained_model=None,\n",
    "                          pretrained=False)\n",
    "\n",
    "single_model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model = torch.nn.DataParallel(single_model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678215d8-8cb6-410d-8bea-30e4409fac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalization required for DRN\n",
    "info = {\"std\": [0.1829540508368939, 0.18656561047509476, 0.18447508988480435], \"mean\": [0.29010095242892997, 0.32808144844279574, 0.28696394422942517]}\n",
    "normalize = transforms.Normalize(mean=info['mean'], std=info['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe39bdf-0fa4-4831-a435-e328fe956eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = ImageDataset(data_dir=im_dir)\n",
    "# Resize later. DRN was trained on the default size, so I imagine it'll work better\n",
    "image_dataset.transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
    "image_loader = DataLoader(image_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed87df21-6b33-4e1a-aa70-d58849f96b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh\\Documents\\cs444\\final_project\\segment_proj.py:258: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  image_var = Variable(image, requires_grad=False, volatile=True)\n",
      "C:\\Users\\Josh\\Documents\\cs444\\final_project\\segment_proj.py:113: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(y), x\n",
      "[2023-05-07 15:10:01,699 segment_proj.py:281 test] Eval: [0/7]\tTime 2.505 (2.505)\tData 0.067 (0.067)\t\n",
      "[2023-05-07 15:10:01,863 segment_proj.py:281 test] Eval: [1/7]\tTime 0.142 (1.323)\tData 0.060 (0.063)\t\n",
      "[2023-05-07 15:10:02,009 segment_proj.py:281 test] Eval: [2/7]\tTime 0.122 (0.923)\tData 0.064 (0.064)\t\n",
      "[2023-05-07 15:10:02,162 segment_proj.py:281 test] Eval: [3/7]\tTime 0.121 (0.722)\tData 0.066 (0.064)\t\n",
      "[2023-05-07 15:10:02,312 segment_proj.py:281 test] Eval: [4/7]\tTime 0.123 (0.603)\tData 0.063 (0.064)\t\n",
      "[2023-05-07 15:10:02,467 segment_proj.py:281 test] Eval: [5/7]\tTime 0.125 (0.523)\tData 0.070 (0.065)\t\n",
      "[2023-05-07 15:10:02,607 segment_proj.py:281 test] Eval: [6/7]\tTime 0.119 (0.465)\tData 0.064 (0.065)\t\n"
     ]
    }
   ],
   "source": [
    "# Outputs lists of PIL images\n",
    "_, outputs, road_masks = test(image_loader, model, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8e9c8a-f0ab-40b8-999f-6b6f6b565d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_list_to_tensor(imgs):\n",
    "    \"\"\"\n",
    "    Converts list of PIL images to tensors\n",
    "    \"\"\"\n",
    "    transform = transforms.ToTensor()\n",
    "    tensor_list = [ transform(img) for img in imgs]\n",
    "\n",
    "    # Concatenate the list of tensors along the first dimension to create a tensor of shape (num_images, channels, height, width)\n",
    "    return torch.stack(tensor_list, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9fac534-facd-4e98-9432-f2fcc307f2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.9569, 0.9569, 0.9569],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.9569, 0.9569, 0.9569],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.9569, 0.9569, 0.9569]],\n",
       "\n",
       "         [[0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          ...,\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.1373, 0.1373, 0.1373]],\n",
       "\n",
       "         [[0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.9098, 0.9098, 0.9098],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.9098, 0.9098, 0.9098],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.9098, 0.9098, 0.9098]]],\n",
       "\n",
       "\n",
       "        [[[0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       "\n",
       "         [[0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          ...,\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510]],\n",
       "\n",
       "         [[0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       "\n",
       "\n",
       "        [[[0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       "\n",
       "         [[0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          ...,\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510]],\n",
       "\n",
       "         [[0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          [0.2745, 0.2745, 0.2745,  ..., 0.2745, 0.2745, 0.2745],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       "\n",
       "         [[0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          ...,\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510]],\n",
       "\n",
       "         [[0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       "\n",
       "\n",
       "        [[[0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       "\n",
       "         [[0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          ...,\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510]],\n",
       "\n",
       "         [[0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]],\n",
       "\n",
       "\n",
       "        [[[0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          [0.4196, 0.4196, 0.4196,  ..., 0.4196, 0.4196, 0.4196],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]],\n",
       "\n",
       "         [[0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          [0.5569, 0.5569, 0.5569,  ..., 0.5569, 0.5569, 0.5569],\n",
       "          ...,\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510],\n",
       "          [0.2510, 0.2510, 0.2510,  ..., 0.2510, 0.2510, 0.2510]],\n",
       "\n",
       "         [[0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          [0.1373, 0.1373, 0.1373,  ..., 0.1373, 0.1373, 0.1373],\n",
       "          ...,\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020],\n",
       "          [0.5020, 0.5020, 0.5020,  ..., 0.5020, 0.5020, 0.5020]]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list_to_tensor(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdfc41-fd53-4334-b38b-ff9f22e0b74f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Labels\n",
    "Use KMeans to figure out colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6e89e8-0a60-4dbd-a462-c5aaa091ad2c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a61869f-c7f5-46fd-b075-02f40fe95d7f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_label_path = ('cityscapes/gtFine/gtFine/train/aachen')\n",
    "train_path = ('cityscapes/leftImg8bit/leftImg8bit/train/aachen')\n",
    "valid_path = glob('cityscapes/gtFine/gtFine/val/*')\n",
    "test_path = glob('cityscapes/gtFine/gtFine/val/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9877ead5-62b1-4e77-8016-83890781f3a9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CropBottomThird(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, image):\n",
    "        height, width = image.size()[-2:]\n",
    "        new_height = height# //2\n",
    "        print(new_height)\n",
    "        return transforms.functional.crop(image, 0, 0, new_height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a32167d6-4f25-4400-9355-09c3ac36acb1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RGB = torchvision.io.ImageReadMode.RGB\n",
    "class CityscapeDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, image_dir, label_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.image_fns = os.listdir(image_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_fns)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_fn = self.image_fns[index]\n",
    "        label_fn = image_fn.replace('leftImg8bit', 'gtFine_color')\n",
    "        \n",
    "        image_fp = os.path.join(self.image_dir, image_fn)\n",
    "        label_fp = os.path.join(self.label_dir, label_fn)\n",
    "        print(image_fp, label_fp)\n",
    "        original = self.transform(read_image(image_fp) /255.0)\n",
    "        original = transforms.Resize((1024, 1024))(original)\n",
    "        \n",
    "        label = self.transform(read_image(label_fp, RGB) / 255.0)\n",
    "        \n",
    "        \n",
    "        # cityscape = self.transform(cityscape)\n",
    "\n",
    "        return original, label\n",
    "    \n",
    "    def transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "            CropBottomThird(),\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "931aa44d-6818-4fbf-9cf2-5f9147a820d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'cityscapes/leftImg8bit/leftImg8bit/train/aachen'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mCityscapeDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 7\u001b[0m, in \u001b[0;36mCityscapeDataset.__init__\u001b[1;34m(self, image_dir, label_dir)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_dir \u001b[38;5;241m=\u001b[39m image_dir\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_dir \u001b[38;5;241m=\u001b[39m label_dir\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_fns \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'cityscapes/leftImg8bit/leftImg8bit/train/aachen'"
     ]
    }
   ],
   "source": [
    "train = CityscapeDataset(train_path, train_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b752104-a689-4be8-ae8b-ba314e8e38c7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422fbdd6-fd2a-4963-b217-3d0197857c43",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cityscape, label_class = train[4]\n",
    "print(cityscape.shape, label_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2b74e-0a86-496c-8a27-f5a5baa149f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tensor_to_im(im):\n",
    "    return rearrange(im, 'C H W -> H W C').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315c24d-537a-43a0-bdd3-853934580e2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def display_im(image):\n",
    "    image = tensor_to_im(image)\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d40a7-fa45-4f65-9788-b08cebda9361",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display_im(cityscape)\n",
    "display_im(label_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dcf810-c507-4e21-8bcd-96e14c492502",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Define Color Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e97f7-7cb0-4d4b-8937-65e72c521457",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# These are the colors for various objects in the segmented image\n",
    "# found at https://github.com/mcordts/cityscapesScripts/blob/master/cityscapesscripts/helpers/labels.py\n",
    "colors = {\n",
    " \"traffic light\": (250,170, 30),\n",
    "    \"traffic sign\": (220,220, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d46d4-964b-47a2-aed5-e289a569c9dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def display_color(color):\n",
    "    # Create a 24x24 array of the color\n",
    "    arr = np.zeros((24, 24, 3), dtype=int)\n",
    "    arr[:, :] = color\n",
    "    \n",
    "    # Display the image using pyplot\n",
    "    plt.imshow(arr)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185c86a-83ae-411c-8d9b-8008b266c8d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_object_mask(object_name, images):\n",
    "    \"\"\"\n",
    "    Takes (batch_size, channels, height, width) image tensor\n",
    "    \"\"\"\n",
    "    color = colors[object_name]\n",
    "    images = rearrange(images, 'N C H W -> N H W C')\n",
    "    mask = torch.all(images[:,:,:]==color)\n",
    "    return rearrange(mask, 'N H W C -> N C H W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a83ee-0d5d-45da-aba5-4d01b96a62ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display_color(colors['traffic light'])\n",
    "display_color(colors['traffic sign'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d93c95-aaf2-4d49-9b5f-f865712eeb5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15a59fa-53b7-448b-8dcd-1c65d1067f60",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "processor = CLIPSegProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cc6e1d-2cac-4a90-81a0-394418fea3cf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = cityscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d12f84-50d6-45af-927f-956de2af631e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prompts = [\"traffic light\", \"car\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67ffa82-f320-4739-9582-0c51706db29e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = processor(text=prompts, images=[image] * len(prompts), padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada2502-37fa-45e5-8d0c-1bccd949bdd5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  outputs = model(**inputs)\n",
    "preds = outputs.logits.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd5ef2-ef9c-4661-98a3-630c555a81a8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, len(prompts) + 1, figsize=(3*(len(prompts) + 1), 4))\n",
    "[a.axis('off') for a in ax.flatten()]\n",
    "ax[0].imshow(tensor_to_im(image))\n",
    "[ax[i+1].imshow((F.softmax(preds[i][0])> 0.01) * 255) for i in range(len(prompts))];\n",
    "[ax[i+1].text(0, -15, prompt) for i, prompt in enumerate(prompts)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2c987a-e186-4bd6-9742-62b60539b6eb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.sum((preds[1][0] > 0.4).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6b8da4-3542-4cae-b533-9c7fd7663dec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.sum(F.softmax(preds[1][0])>0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23396949-b5a4-42a3-b060-9cb503c90b75",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd191d-8cfe-45a6-b96a-3f7605cf8443",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import SegformerForSemanticSegmentation, SegformerFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144fefc-bb64-40bd-966d-bad36745898a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor = SegformerFeatureExtractor.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\")\n",
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/segformer-b0-finetuned-cityscapes-1024-1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a0908-2f8d-4539-b2bb-5a97eeac39e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = cityscape\n",
    "inputs = feature_extractor(images=image, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "logits = outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e75e4bb-63ad-472f-b36d-059516a3d235",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# First, rescale logits to original image size\n",
    "upsampled_logits = F.interpolate(logits,\n",
    "                size=(1024,1024), # (height, width)\n",
    "                mode='bilinear',\n",
    "                align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592bde6-1722-45b0-965f-6c2fce42f8c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "upsampled_logits.argmax(dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddbfbc9-64c0-47ed-bf29-c95437012434",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Second, apply argmax on the class dimension\n",
    "seg = upsampled_logits.argmax(dim=1).squeeze(0)\n",
    "color_seg = np.zeros((seg.shape[0], seg.shape[1], 3), dtype=np.uint8) # height, width, 3\n",
    "for label_id, color in id2color.items():\n",
    "    color_seg[seg == label_id, :] = color\n",
    "# Convert to BGR\n",
    "color_seg = color_seg[..., ::-1]\n",
    "\n",
    "# Show image + mask\n",
    "img = np.array(rearrange(image, 'C H W -> H W C')) * 0.5 + color_seg * 0.5\n",
    "img = img.astype(np.uint8)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99e8c90-8d6a-461b-b742-92f0f96f11cb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
